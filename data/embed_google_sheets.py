import os
import json
import hashlib
import pickle
from datetime import datetime

import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from sentence_transformers import SentenceTransformer

from dotenv import load_dotenv

load_dotenv()

SPREADSHEET_ID = os.getenv("GOOGLE_SHEET_ID")
META_DIR = "data/metadata"
EMD_DIR = "data/embeddings"
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"

def get_gspread_client():
    service_account_inf = {
        "type": os.getenv("GOOGLE_TYPE"),
        "project_id": os.getenv("GOOGLE_PROJECT_ID"),
        "private_key": os.getenv("GOOGLE_PRIVATE_KEY"),
        "client_email": os.getenv("GOOGLE_CLIENT_EMAIL"),
        "client_id": os.getenv("GOOGLE_CLIENT_ID"),
        "auth_uri": os.getenv("GOOGLE_AUTH_URI"),
        "token_uri": os.getenv("GOOGLE_TOKEN_URI"),
        "auth_provider_x509_cert_url": os.getenv("GOOGLE_AUTH_PROVIDER_x509_CERT_URL"),
        "client_x509_cert_url": os.getenv("GOOGLE_CLIENT_x509_CERT_URL"),
        "universe_domain": os.getenv("GOOGLE_UNIVERSE_DOMAIN")
    }
    scopes = ["https://www.googleapis.com/auth/spreadsheets.readonly"]
    creds = Credentials.from_service_account_info(service_account_inf, scopes=scopes)
    return gspread.authorize(creds)

# TEST CONNECTION

# if __name__ == "__main__":
#     try:
#         print("Testing Google Sheet connection...")
#         client = get_gspread_client()
#         sheet = client.open_by_key(SPREADSHEET_ID)
#         print(f"Connected to spreadsheet: {sheet.title}")

#     except Exception as e:
#         print("Connection failed!")
#         print(e)

def hash_dataframe(df: pd.DataFrame) -> str:
    return hashlib.md5(pd.util.hash_pandas_object(df, index=True).values).hexdigest()

def load_metadata_files(meta_dir: str):
    return [
        os.path.join(meta_dir, f)
        for f in os.listdir(meta_dir)
        if f.endswith(".json")
    ]

def load_google_sheet(client , sheet_id: str, sheet_name: str) -> pd.DataFrame:
    worksheet = client.open_by_key(sheet_id).worksheet(sheet_name)
    return pd.DataFrame(worksheet.get_all_records())

def save_embeddings(sheet_name, df, embeddings_by_col, data_hash):
    save_path = f"{EMD_DIR}/{sheet_name}.pkl"
    data = {
        "sheet_name": sheet_name,
        "embeddings_by_col": {
            col: {
                "texts": df[col].astype(str).tolist(),
                "embeddings": embeddings_by_col[col],
            }
            for col in embeddings_by_col
        },
        "updated_at": datetime.now().isoformat(),
        "data_hash": data_hash,
    }
    with open(save_path, "wb") as f:
        pickle.dump(data, f)
    print(f"ƒê√£ l∆∞u embedding: {save_path}")

def update_metadata(meta_path: str, data_hash: str):
    """C·∫≠p nh·∫≠t hash v√† th·ªùi gian v√†o metadata."""
    meta = json.load(open(meta_path, "r"))
    # N·∫øu l√† list, c·∫≠p nh·∫≠t ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n (ho·∫∑c t·∫•t c·∫£ n·∫øu mu·ªën)
    if isinstance(meta, list):
        for m in meta:
            m["data_hash"] = data_hash
            m["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    elif isinstance(meta, dict):
        meta["data_hash"] = data_hash
        meta["updated_at"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    json.dump(meta, open(meta_path, "w"), indent=2, ensure_ascii=False)


# ==============================
# MAIN LOGIC
# ==============================
def process_sheet(meta_path: str, client, model):
    metas = json.load(open(meta_path, "r"))

    # N·∫øu file l√† 1 dict duy nh·∫•t, th√¨ chuy·ªÉn th√†nh list 1 ph·∫ßn t·ª≠ ƒë·ªÉ th·ªëng nh·∫•t
    if isinstance(metas, dict):
        metas = [metas]

    for meta in metas:
        sheet_name = meta["sheet_name"].strip()
        columns = meta.get("column", [])
        print(f"\nƒêang x·ª≠ l√Ω sheet: {sheet_name}")

        # ƒê·ªçc sheet
        try:
            df = load_google_sheet(client, SPREADSHEET_ID, sheet_name)
        except gspread.exceptions.WorksheetNotFound:
            print(f"Kh√¥ng t√¨m th·∫•y sheet '{sheet_name}', b·ªè qua.")
            continue

        # L·ªçc c·ªôt c·∫ßn thi·∫øt
        selected = [c for c in columns if c in df.columns]
        if not selected:
            print(f"Sheet '{sheet_name}' kh√¥ng c√≥ c·ªôt tr√πng v·ªõi metadata.")
            continue

        df = df[selected]
        df["text"] = df.astype(str).apply(lambda r: " | ".join(r.values), axis=1)
        df = df[df["text"].str.strip() != ""]

        # Ki·ªÉm tra thay ƒë·ªïi
        new_hash = hash_dataframe(df)
        if new_hash == meta.get("data_hash"):
            print(f"{sheet_name}: D·ªØ li·ªáu kh√¥ng ƒë·ªïi, b·ªè qua embedding.")
            continue

        # T·∫°o embeddings
        print(f"üß† T·∫°o embeddings cho {len(df)} d√≤ng...")
        embeddings = model.encode(df["text"].tolist(), show_progress_bar=True, convert_to_numpy=True)

        # L∆∞u k·∫øt qu·∫£
        save_embeddings(sheet_name, df, {"text": embeddings}, new_hash)
        update_metadata(meta_path, new_hash)
        print(f"Ho√†n t·∫•t: {sheet_name}")

# ==============================
# ENTRY POINT
# ==============================
def main():
    print("B·∫Øt ƒë·∫ßu embedding pipeline...")
    client = get_gspread_client()
    model = SentenceTransformer(MODEL_NAME)

    meta_files = load_metadata_files(META_DIR)
    if not meta_files:
        print("Kh√¥ng t√¨m th·∫•y file metadata n√†o.")
        return

    for meta_path in meta_files:
        process_sheet(meta_path, client, model)

    print("\nHo√†n th√†nh to√†n b·ªô embedding pipeline!")


if __name__ == "__main__":
    main()